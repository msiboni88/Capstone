{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mags/anaconda3/lib/python3.7/site-packages/dask/config.py:168: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  data = yaml.load(f.read()) or {}\n"
     ]
    }
   ],
   "source": [
    "# Importing libraries to access files; adjust images\n",
    "import os\n",
    "from skimage import io\n",
    "from skimage.color import rgb2gray\n",
    "from skimage.transform import rescale, resize, downscale_local_mean\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image paths\n",
    "muffin_path = './muffin images/'\n",
    "chihuahua_path = './chihuahua/'\n",
    "\n",
    "# specify crop size of images to be used\n",
    "set_width = 300\n",
    "set_height = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mags/anaconda3/lib/python3.7/site-packages/skimage/transform/_warps.py:105: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
      "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "Processed 20 out of 1661 images.\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "Processed 40 out of 1661 images.\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "Processed 60 out of 1661 images.\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "Processed 80 out of 1661 images.\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "Processed 100 out of 1661 images.\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "Processed 120 out of 1661 images.\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "130\n",
      "131\n",
      "132\n",
      "133\n",
      "134\n",
      "135\n",
      "136\n",
      "137\n",
      "138\n",
      "139\n",
      "Processed 140 out of 1661 images.\n",
      "140\n",
      "141\n",
      "142\n",
      "143\n",
      "144\n",
      "145\n",
      "146\n",
      "147\n",
      "148\n",
      "149\n",
      "150\n",
      "151\n",
      "152\n",
      "153\n",
      "154\n",
      "155\n",
      "156\n",
      "157\n",
      "158\n",
      "159\n",
      "Processed 160 out of 1661 images.\n",
      "160\n",
      "161\n",
      "162\n",
      "163\n",
      "164\n",
      "165\n",
      "166\n",
      "167\n",
      "168\n",
      "169\n",
      "170\n",
      "171\n",
      "172\n",
      "173\n",
      "174\n",
      "175\n",
      "176\n",
      "177\n",
      "178\n",
      "179\n",
      "Processed 180 out of 1661 images.\n",
      "180\n",
      "181\n",
      "182\n",
      "183\n",
      "184\n",
      "185\n",
      "186\n",
      "187\n",
      "188\n",
      "189\n",
      "190\n",
      "191\n",
      "192\n",
      "193\n",
      "194\n",
      "195\n",
      "196\n",
      "197\n",
      "198\n",
      "199\n",
      "Processed 200 out of 1661 images.\n",
      "200\n",
      "201\n",
      "202\n",
      "203\n",
      "204\n",
      "205\n",
      "206\n",
      "207\n",
      "208\n",
      "209\n",
      "210\n",
      "211\n",
      "212\n",
      "213\n",
      "214\n",
      "215\n",
      "216\n",
      "217\n",
      "218\n",
      "219\n",
      "Processed 220 out of 1661 images.\n",
      "220\n",
      "221\n",
      "222\n",
      "223\n",
      "224\n",
      "225\n",
      "226\n",
      "227\n",
      "228\n",
      "229\n",
      "230\n",
      "231\n",
      "232\n",
      "233\n",
      "234\n",
      "235\n",
      "236\n",
      "237\n",
      "238\n",
      "239\n",
      "Processed 240 out of 1661 images.\n",
      "240\n",
      "241\n",
      "242\n",
      "243\n",
      "244\n",
      "245\n",
      "246\n",
      "247\n",
      "248\n",
      "249\n",
      "250\n",
      "251\n",
      "252\n",
      "253\n",
      "254\n",
      "255\n",
      "256\n",
      "257\n",
      "258\n",
      "259\n",
      "Processed 260 out of 1661 images.\n",
      "260\n",
      "261\n",
      "262\n",
      "263\n",
      "264\n",
      "265\n",
      "266\n",
      "267\n",
      "268\n",
      "269\n",
      "270\n",
      "271\n",
      "272\n",
      "273\n",
      "274\n",
      "Error at .DS_Store\n",
      "275\n",
      "276\n",
      "277\n",
      "278\n",
      "279\n",
      "Processed 280 out of 1661 images.\n",
      "280\n",
      "281\n",
      "282\n",
      "283\n",
      "284\n",
      "285\n",
      "286\n",
      "287\n",
      "288\n",
      "289\n",
      "290\n",
      "291\n",
      "292\n",
      "293\n",
      "294\n",
      "295\n",
      "296\n",
      "297\n",
      "298\n",
      "299\n",
      "Processed 300 out of 1661 images.\n",
      "300\n",
      "301\n",
      "302\n",
      "303\n",
      "304\n",
      "305\n",
      "306\n",
      "307\n",
      "308\n",
      "309\n",
      "310\n",
      "311\n",
      "312\n",
      "313\n",
      "314\n",
      "315\n",
      "316\n",
      "317\n",
      "318\n",
      "319\n",
      "Processed 320 out of 1661 images.\n",
      "320\n",
      "321\n",
      "322\n",
      "323\n",
      "324\n",
      "325\n",
      "326\n",
      "327\n",
      "328\n",
      "329\n",
      "330\n",
      "331\n",
      "332\n",
      "333\n",
      "334\n",
      "335\n",
      "336\n",
      "337\n",
      "338\n",
      "339\n",
      "Processed 340 out of 1661 images.\n",
      "340\n",
      "341\n",
      "342\n",
      "343\n",
      "344\n",
      "345\n",
      "346\n",
      "347\n",
      "348\n",
      "349\n",
      "350\n",
      "351\n",
      "352\n",
      "353\n",
      "354\n",
      "355\n",
      "356\n",
      "357\n",
      "358\n",
      "359\n",
      "Processed 360 out of 1661 images.\n",
      "360\n",
      "361\n",
      "362\n",
      "363\n",
      "364\n",
      "365\n",
      "366\n",
      "367\n",
      "368\n",
      "369\n",
      "370\n"
     ]
    }
   ],
   "source": [
    "# function to greyscale, crop, resize and add to an array a file of images \n",
    "\n",
    "image_list = os.listdir(muffin_path)\n",
    "\n",
    "# empty array to stack all images in\n",
    "m_array = np.zeros([set_width, set_height, len(image_list)])\n",
    "\n",
    "# loop through 100 images at a time\n",
    "for i, image_name in enumerate(image_list):\n",
    "    print(i)\n",
    "    try:\n",
    "        # reading image; making greyscale\n",
    "        image = rgb2gray(io.imread(muffin_path+image_name))\n",
    "\n",
    "        # loading height and width to determine: \n",
    "        # which dimension ism smaller (to make 1500)\n",
    "        # where to crop larger dimension to center image\n",
    "        image_height = image.shape[0]\n",
    "        image_width = image.shape[1]\n",
    "\n",
    "        if image_height > image_width:\n",
    "            #resizing\n",
    "            multiplier = set_width/image_width\n",
    "            new_height = int(image_height*multiplier)\n",
    "            image_resized = resize(image, (new_height, 300), anti_aliasing=True)\n",
    "\n",
    "             #cropping\n",
    "            crop_cut = int((new_height-300)/2)\n",
    "            cropped = image_resized[crop_cut:crop_cut+300, 0:300]\n",
    "\n",
    "\n",
    "        else: \n",
    "            #resizing\n",
    "            multiplier = set_height/image_height\n",
    "            new_width = int(image_width*multiplier)\n",
    "            image_resized = resize(image, (300, new_width), anti_aliasing=True)\n",
    "\n",
    "            #cropping\n",
    "            crop_cut = int((new_width-300)/2)\n",
    "            cropped = image_resized[0:300, crop_cut:crop_cut+300]\n",
    "\n",
    "            # add to image stack\n",
    "\n",
    "        m_array[:,:,i] = cropped\n",
    "        if (i+1)%20 == 0:\n",
    "            np.save('./files/m_array.npy', m_array, True)\n",
    "            print(f'Processed {i+1} out of {len(image_list)} images.')\n",
    "\n",
    "    except:\n",
    "        print(f'Error at {image_name}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 20 out of 300 images.\n",
      "Processed 40 out of 300 images.\n",
      "Error at IMG_1281.jpg\n",
      "Processed 60 out of 300 images.\n",
      "Processed 80 out of 300 images.\n",
      "Processed 100 out of 300 images.\n",
      "Processed 120 out of 300 images.\n",
      "Error at IMG_1912.HEIC\n",
      "Processed 140 out of 300 images.\n",
      "Error at IMG_4225.HEIC\n",
      "Error at IMG_1027.HEIC\n",
      "Processed 160 out of 300 images.\n",
      "Error at IMG_1282.jpg\n",
      "Processed 180 out of 300 images.\n",
      "Processed 200 out of 300 images.\n"
     ]
    }
   ],
   "source": [
    "# function to greyscale, crop, resize and add to an array a file of images \n",
    "\n",
    "image_list = os.listdir(chihuahua_path)\n",
    "\n",
    "# empty array to stack all images in\n",
    "c_array_1 = np.zeros([set_width, set_height, 200])\n",
    "\n",
    "# loop through 100 images at a time\n",
    "for i, image_name in enumerate(image_list[:200]):\n",
    "    try:\n",
    "        # reading image; making greyscale\n",
    "        image = rgb2gray(io.imread(chihuahua_path+image_name))\n",
    "\n",
    "        # loading height and width to determine: \n",
    "        # which dimension ism smaller (to make 1500)\n",
    "        # where to crop larger dimension to center image\n",
    "        image_height = image.shape[0]\n",
    "        image_width = image.shape[1]\n",
    "\n",
    "        if image_height > image_width:\n",
    "            #resizing\n",
    "            multiplier = set_width/image_width\n",
    "            new_height = int(image_height*multiplier)\n",
    "            image_resized = resize(image, (new_height, 1500), anti_aliasing=True)\n",
    "\n",
    "             #cropping\n",
    "            crop_cut = int((new_height-1500)/2)\n",
    "            cropped = image_resized[crop_cut:crop_cut+1500, 0:1500]\n",
    "\n",
    "\n",
    "        else: \n",
    "            #resizing\n",
    "            multiplier = set_height/image_height\n",
    "            new_width = int(image_width*multiplier)\n",
    "            image_resized = resize(image, (1500, new_width), anti_aliasing=True)\n",
    "\n",
    "            #cropping\n",
    "            crop_cut = int((new_width-1500)/2)\n",
    "            cropped = image_resized[0:1500, crop_cut:crop_cut+1500]\n",
    "\n",
    "            # add to image stack\n",
    "\n",
    "        c_array_1[:,:,i] = cropped\n",
    "        if (i+1)%20 == 0:\n",
    "            np.save('./files/c_array_1.npy', c_array_1, True)\n",
    "            print(f'Processed {i+1} out of 300 images.')\n",
    "\n",
    "    except:\n",
    "        print(f'Error at {image_name}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 20 out of 200 images.\n",
      "Processed 40 out of 200 images.\n",
      "Processed 60 out of 200 images.\n",
      "Processed 80 out of 200 images.\n",
      "Processed 100 out of 200 images.\n",
      "Error at 78.vaarikamuffin_5.jpg\n",
      "Processed 120 out of 200 images.\n",
      "Processed 140 out of 200 images.\n",
      "Processed 160 out of 200 images.\n",
      "Processed 180 out of 200 images.\n",
      "Processed 200 out of 200 images.\n"
     ]
    }
   ],
   "source": [
    "image_list = os.listdir(chihuahua_path)\n",
    "image_count = len(image_list)\n",
    "# empty array to stack all images in\n",
    "c_array_1 = np.zeros([set_width, set_height, 200])\n",
    "\n",
    "# loop through 100 images at a time\n",
    "for i, image_name in enumerate(image_list[:200]):\n",
    "    try:\n",
    "        # reading image; making greyscale\n",
    "        image = rgb2gray(io.imread(chihuahua_path+image_name))\n",
    "\n",
    "        # loading height and width to determine: \n",
    "        # which dimension ism smaller (to make 1500)\n",
    "        # where to crop larger dimension to center image\n",
    "        image_height = image.shape[0]\n",
    "        image_width = image.shape[1]\n",
    "\n",
    "        if image_height > image_width:\n",
    "            #resizing\n",
    "            multiplier = set_width/image_width\n",
    "            new_height = int(image_height*multiplier)\n",
    "            image_resized = resize(image, (new_height, 1500), anti_aliasing=True)\n",
    "\n",
    "             #cropping\n",
    "            crop_cut = int((new_height-1500)/2)\n",
    "            cropped = image_resized[crop_cut:crop_cut+1500, 0:1500]\n",
    "\n",
    "\n",
    "        else: \n",
    "            #resizing\n",
    "            multiplier = set_height/image_height\n",
    "            new_width = int(image_width*multiplier)\n",
    "            image_resized = resize(image, (1500, new_width), anti_aliasing=True)\n",
    "\n",
    "            #cropping\n",
    "            crop_cut = int((new_width-1500)/2)\n",
    "            cropped = image_resized[0:1500, crop_cut:crop_cut+1500]\n",
    "\n",
    "            # add to image stack\n",
    "\n",
    "        c_array_1[:,:,i] = cropped\n",
    "        if (i+1)%20 == 0:\n",
    "            np.save('./files/c_array_1.npy', c_array_1, True)\n",
    "            print(f'Processed {i+1} out of 300 images.')\n",
    "\n",
    "    except:\n",
    "        print(f'Error at {image_name}')\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
